{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBDS - DSF - Final Project\n",
    "## By Ennio Maldonado\n",
    "### Whatami?!\n",
    "A container deployment for a web application in flask that uses a convolutional neural network to classify images into 10 possible classes using the CIFAR-10 annotated data set and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n",
    "The CIFAR-10 dataset\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each:\n",
    "![cifar10](cifar10.png)\t\t\t\t\n",
    "\n",
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks. \n",
    "\n",
    "You can find some baseline replicable results on this dataset on the project page for cuda-convnet. These results were obtained with a convolutional neural network. Briefly, they are 18% test error without data augmentation and 11% with. Additionally, Jasper Snoek has a new paper in which he used Bayesian hyperparameter optimization to find nice settings of the weight decay and other hyperparameters, which allowed him to obtain a test error rate of 15% (without data augmentation) using the architecture of the net that got 18%.\n",
    "Other results\n",
    "\n",
    "### Dataset layout\n",
    "#### Python / Matlab versions\n",
    "\n",
    "I will describe the layout of the Python version of the dataset. The layout of the Matlab version is identical.\n",
    "\n",
    "The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle. Here is a python2 routine which will open such a file and return a dictionary:\n",
    "\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "And a python3 version:\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "\n",
    "* data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "* labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "\n",
    "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
    "\n",
    "* label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cifar10 from keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import resize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is already split into 50k train data and 10k test data so we only need to assing it.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data consist of 50k images that are 32 pixels heihgt, 32 pixels width and are RGB.\n",
    "print('shape of features from training data:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The annotations consist of 50k labels (numebrs from 0 to 9 corresponding to the labels).\n",
    "print('shape of target/labels from training data:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are:\n",
    "\n",
    "![labels](cifar20_labels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing a sample of the images\n",
    "im_size=15\n",
    "im_rows = 5\n",
    "im_col = 5\n",
    "fig, axes = plt.subplots(im_rows,im_col,figsize=(im_size,im_size))\n",
    "k=0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i,j].imshow(x_train[k])\n",
    "        axes[i,j].set_title(f'Label: {y_train[k]}',fontsize=im_size)\n",
    "        axes[i,j].set_axis_off()\n",
    "        k+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "I will be using 10 output neurons because the data has 10 classes, in order to be able to pass it to the model we need to have it in the format [0 0 0 0 0 0 0 0 0 1], for this will use keral utility to categorical in order to onehot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for encoding\n",
    "def one_hot_encoding(dataset, classes):\n",
    "    return keras.utils.to_categorical(dataset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliying one hot encoding\n",
    "y_train_encoded = one_hot_encoding(y_train, 10)\n",
    "y_test_encoded = one_hot_encoding(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The encoded label is: {y_train_encoded[0]}, and the normal label is:_ {y_train[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally neural networks are easier to train with normalized data, in order to normalize our data we will get the max and divide the data set by the mas, in this case since the images already go from 0 to 255, we only need to divide by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for normalizing \n",
    "def normalize(dataset):\n",
    "    return dataset.astype('float32') / x_train.max()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization \n",
    "x_train_norm = normalize(x_train)\n",
    "x_test_norm = normalize(x_test)\n",
    "head, *tail = x_train_norm\n",
    "head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Template / Archutecture of the CNN\n",
    "\n",
    "Taken from josephlee94 on github.\n",
    "\n",
    "ReLu activation for all layers except the output layer which is Softmax\n",
    "\n",
    "* Conv Layer (Filter size 3x3, Depth 32) // The filter to predict based on parameters\n",
    "* Conv Layer (Filter size 3x3, Depth 32) // Another layer\n",
    "* Max Pool Layer (Filter size 2x2) // Get the max predicted value out of a 2 x 2 matrix\n",
    "* Dropout Layer (Prob of dropout 0.25) // drop out layer for regularization\n",
    "* Conv Layer (Filter size 3x3, Depth 64) // another layer\n",
    "* Conv Layer (Filter size 3x3, Depth 64) // another layer\n",
    "* Max Pool Layer (Filter size 2x2) // once again reduce dimentionality \n",
    "* Dropout Layer (Prob of dropout 0.25) // more regularization\n",
    "* FC Layer (512 neurons) // Linear combinations \n",
    "* Dropout Layer (Prob of dropout 0.5) // normalization\n",
    "* FC Layer, Softmax (10 neurons) // Output Layer Softmax - to prob distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will using the sequential model\n",
    "modelo_chingon = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1: Convolutional Neuron, with depth = 32, filter = 3x3, \n",
    "# padding = same so that output has the same shape as the input.\n",
    "# stride will be 1 the images are very small after all.\n",
    "modelo_chingon.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))\n",
    "# Layer 2: Same as layer 1, ecept we don't need to specfy shape anymore,\n",
    "# is inferred from previous layer.\n",
    "modelo_chingon.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Layer 3: Max Pool, filter = 2x2,\n",
    "modelo_chingon.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Layer 4: Dropout, prob = 0.25 for regularization,\n",
    "modelo_chingon.add(Dropout(0.25))\n",
    "# Similarly for Layers 5 to 8, exceot the depth in the convolutional layer is of 64\n",
    "modelo_chingon.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "modelo_chingon.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "modelo_chingon.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelo_chingon.add(Dropout(0.25))\n",
    "# Flatten Layer to from Cube shape of depth 32 to a row.\n",
    "modelo_chingon.add(Flatten())\n",
    "# FC Layer of 512 Neurons\n",
    "modelo_chingon.add(Dense(512, activation='relu'))\n",
    "# Layer 10: Another dropout\n",
    "modelo_chingon.add(Dropout(0.5))\n",
    "# Output Layer with softmax activation\n",
    "modelo_chingon.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full summary of the layers:\n",
    "modelo_chingon.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not implemented yet\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to compile the model we use categorical cross entropy, which is good for many categories,\n",
    "# the optimizer will be Adam which is a modified stochastic gradient descent,\n",
    "# Finally we will track the accuracy of the model\n",
    "modelo_chingon.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy','Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it!!\n",
    "# Batch size of 32 with 20 epochs\n",
    "# Trick to split 20% for validation at training step\n",
    "hist = modelo_chingon.fit(x_train_norm, y_train_encoded, \n",
    "        batch_size=32, epochs=30,\n",
    "        validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the model loss and accuraccy\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(40,10))\n",
    "\n",
    "axes[0].plot(hist.history['loss'])\n",
    "axes[0].plot(hist.history['val_loss'])\n",
    "axes[0].set_title('Model loss', fontsize= 40)\n",
    "axes[0].set_ylabel('Loss', fontsize= 30)\n",
    "axes[0].set_xlabel('Epoch', fontsize= 30)\n",
    "axes[0].legend(['Train', 'Val'], loc='upper right')\n",
    "\n",
    "axes[1].plot(hist.history['accuracy'])\n",
    "axes[1].plot(hist.history['val_accuracy'])\n",
    "axes[1].set_title('Model accuracy', fontsize= 40)\n",
    "axes[1].set_ylabel('Accuracy', fontsize= 30)\n",
    "axes[1].set_xlabel('Epoch', fontsize= 30)\n",
    "axes[1].legend(['Train', 'Val'], loc='lower right')\n",
    "\n",
    "axes[2].plot(hist.history['precision'])\n",
    "axes[2].plot(hist.history['val_precision'])\n",
    "axes[2].set_title('Model Precision', fontsize= 40)\n",
    "axes[2].set_ylabel('Precision', fontsize= 30)\n",
    "axes[2].set_xlabel('Epoch', fontsize= 30)\n",
    "axes[2].legend(['Train', 'Val'], loc='lower right')\n",
    "\n",
    "axes[3].plot(hist.history['recall'])\n",
    "axes[3].plot(hist.history['val_recall'])\n",
    "axes[3].set_title('Model Recall', fontsize= 40)\n",
    "axes[3].set_ylabel('Recall', fontsize= 30)\n",
    "axes[3].set_xlabel('Epoch', fontsize= 30)\n",
    "axes[3].legend(['Train', 'Val'], loc='lower right')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(which='both', labelsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally time to pass it to the test data it has never seen.\n",
    "modelo_chingon.evaluate(x_test_norm, y_test_encoded)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el Modelo\n",
    "modelo_chingon.save('cifar10_chingon.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('cifar10_chingon.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model as lm   \n",
    "from keras.preprocessing.image import img_to_array        \n",
    "from keras.applications import imagenet_utils            \n",
    "from PIL import Image                     \n",
    "import numpy as np               \n",
    "import flask                  \n",
    "import io              \n",
    "\n",
    "def load_model():                                                                         \n",
    "    # load the pre-trained Keras model (here we are using a model                         \n",
    "    # pre-trained on ImageNet and provided by Keras, but you can                          \n",
    "    # substitute in your own networks just as easily)                                     \n",
    "    global model                                                                          \n",
    "    model = lm('cifar10_chingon.h5')       \n",
    "\n",
    "def prepare_image(image, target):                              \n",
    "    # if the image mode is not RGB, convert it             \n",
    "    if image.mode != \"RGB\":                                          \n",
    "        image = image.convert(\"RGB\")                    \n",
    "    # resize the input image and preprocess it           \n",
    "    image = image.resize(target)              \n",
    "    image = img_to_array(image)                            \n",
    "    image = np.expand_dims(image, axis=0)                 \n",
    "    image = imagenet_utils.preprocess_input(image)            \n",
    "    # return the processed image                  \n",
    "    return image                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  \n",
    "model = lm('cifar10_chingon.h5')\n",
    "#Load the image\n",
    "img = Image.open('cat.jpeg')\n",
    "image = prepare_image(img, target=(32, 32))      \n",
    "# classify the input image and then initialize the list       \n",
    "# of predictions to return to the client                  \n",
    "preds = model.predict(image)                 \n",
    "\n",
    "                   \n",
    "#for (imagenetID, label, prob) in results[0]:    \n",
    "#    r = {\"label\": label, \"probability\": float(prob)}   \n",
    "#    data[\"predictions\"].append(r)             \n",
    "#    # indicate that the request was a success         \n",
    "#    data[\"success\"] = True     \n",
    "preds\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def probabilities(preds, classes):\n",
    "    return sorted(dict(zip(classes, *preds.tolist())).items(), key=lambda t: t[1], reverse=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = probabilities(preds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"success\": False} \n",
    "data[\"predictions\"] = []                   \n",
    "for (label, prob) in probas:    \n",
    "    r = {\"label\": label, \"probability\": float(prob)}   \n",
    "    data[\"predictions\"].append(r)             \n",
    "    # indicate that the request was a success         \n",
    "    data[\"success\"] = True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'predictions': [{'label': 'cat', 'probability': 1.0},\n",
       "  {'label': 'airplane', 'probability': 5.839614110306482e-28},\n",
       "  {'label': 'automobile', 'probability': 0.0},\n",
       "  {'label': 'bird', 'probability': 0.0},\n",
       "  {'label': 'deer', 'probability': 0.0},\n",
       "  {'label': 'dog', 'probability': 0.0},\n",
       "  {'label': 'frog', 'probability': 0.0},\n",
       "  {'label': 'horse', 'probability': 0.0},\n",
       "  {'label': 'ship', 'probability': 0.0},\n",
       "  {'label': 'truck', 'probability': 0.0}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
